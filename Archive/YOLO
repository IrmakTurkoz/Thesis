{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO","provenance":[],"collapsed_sections":["MssBAzaADqF_","Ahfgsso_A4U-"],"authorship_tag":"ABX9TyPkkao9M6IGbb2gMOwgpVvZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9m7dKdp_5_fq","executionInfo":{"status":"ok","timestamp":1643032637742,"user_tz":-180,"elapsed":56653,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"82234d5d-207e-4985-e9bf-ebffed39032f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","MyDrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls /content/gdrive"]},{"cell_type":"code","source":["# Enable GPU dynamic memory allocation\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)"],"metadata":{"id":"fZ7D0jiXFghU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.extend(['/content/models/research/', '/content/models/research/slim/'])"],"metadata":{"id":"YDdyE0GN9CXg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/gdrive/My\\ Drive/Thesis/MovieLens20M"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEoAM5jU6Gve","executionInfo":{"status":"ok","timestamp":1643032638178,"user_tz":-180,"elapsed":440,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"a24cccae-5db0-4209-e08e-bdb4f0e2b367"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/Thesis/MovieLens20M\n"]}]},{"cell_type":"code","source":["!pip install decord"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4eIWxCt7tEn","executionInfo":{"status":"ok","timestamp":1643032643088,"user_tz":-180,"elapsed":4915,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"5f5a0d70-1f8a-4c17-bf80-7401ebff91cb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting decord\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[K     |████████████████████████████████| 13.6 MB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord) (1.19.5)\n","Installing collected packages: decord\n","Successfully installed decord-0.6.0\n"]}]},{"cell_type":"code","source":["!pip install tensorflow-object-detection-api"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Em62BbzzGyJO","executionInfo":{"status":"ok","timestamp":1643032650820,"user_tz":-180,"elapsed":7738,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"552fa314-1dd9-4d0e-fb2b-156a823627e1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-object-detection-api\n","  Downloading tensorflow_object_detection_api-0.1.1.tar.gz (577 kB)\n","\u001b[?25l\r\u001b[K     |▋                               | 10 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 143 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 204 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 256 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 266 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 276 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 296 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 317 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 348 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 358 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 368 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 389 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 399 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 409 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 419 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 430 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 440 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 460 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 471 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 481 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 491 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 501 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 512 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 522 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 532 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 542 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 552 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 563 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 573 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 577 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.1.2)\n","Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n","Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.26)\n","Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.17.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (2.7.0)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.37.1)\n","Collecting twine\n","  Downloading twine-3.7.1-py3-none-any.whl (35 kB)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.5)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (1.0.18)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (57.4.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.5)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (5.1.3)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (0.2.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.2)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.9.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.3.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (0.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (3.10.0.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (3.7.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.12.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (22.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (2.8.2)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (2.0.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.19.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (4.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.5.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (21.3)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (2.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.43.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.7.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.7.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.4.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (12.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.23.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.12.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.13.3)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.7.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->tensorflow-object-detection-api) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.35.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->tensorflow-object-detection-api) (3.1.1)\n","Collecting colorama>=0.4.3\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting readme-renderer>=21.0\n","  Downloading readme_renderer-32.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.62.3)\n","Collecting keyring>=15.1\n","  Downloading keyring-23.5.0-py3-none-any.whl (33 kB)\n","Collecting requests-toolbelt!=0.9.0,>=0.8.0\n","  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 4.0 MB/s \n","\u001b[?25hCollecting rfc3986>=1.4.0\n","  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n","Collecting pkginfo>=1.8.1\n","  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n","Collecting SecretStorage>=3.2\n","  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n","Collecting jeepney>=0.4.2\n","  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.17.1)\n","Collecting cryptography>=2.0\n","  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 54.6 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (2.21)\n","Building wheels for collected packages: tensorflow-object-detection-api\n","  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-py3-none-any.whl size=844512 sha256=80d1d2c8b70152024ca240605c23cb57f250f63283724924e2c47e8979d2f824\n","  Stored in directory: /root/.cache/pip/wheels/71/7e/a2/461ab817fbaef68ec9cc60df16d3669d1285f032e4c98179bf\n","Successfully built tensorflow-object-detection-api\n","Installing collected packages: jeepney, cryptography, SecretStorage, rfc3986, requests-toolbelt, readme-renderer, pkginfo, keyring, colorama, twine, tensorflow-object-detection-api\n","Successfully installed SecretStorage-3.3.1 colorama-0.4.4 cryptography-36.0.1 jeepney-0.7.1 keyring-23.5.0 pkginfo-1.8.2 readme-renderer-32.0 requests-toolbelt-0.9.1 rfc3986-2.0.0 tensorflow-object-detection-api-0.1.1 twine-3.7.1\n"]}]},{"cell_type":"code","source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"metadata":{"id":"qGwLjxWt7vZT","executionInfo":{"status":"ok","timestamp":1643033146251,"user_tz":-180,"elapsed":495442,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c42527d5-af03-470f-c50a-bb83075b4fa7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/gdrive/My Drive/Thesis/MovieLens20M/models/research\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.35.0-cp37-cp37m-manylinux2010_x86_64.whl (9.9 MB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.26)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n","Collecting tensorflow_io\n","  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","Collecting tensorflow-text>=2.7.0\n","  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.6)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.23.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.6-cp37-cp37m-manylinux_2_24_x86_64.whl (245 kB)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.19.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.10)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.5.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=09e99bc96878cceaf552700355385e833ff588a7a559e84495f6e4036e19f087\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3i57ddez/wheels/fa/49/bc/61477ec4e0b356a5c13821b933b6b6e8fe7f3e8350f61c6306\n","  Building wheel for py-cpuinfo (setup.py): started\n","  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=e9794be4826cda970b23834377740c9e028e0b25b4a1e2a35151f9e755f0b47d\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=5f37ee2afeaa706757970c5b1944833979ce2ff4f6659437602877bd25a431bd\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=e26df884b7294bcc745db250c5ba0476cbbde2bde09cf0d3a00809dc07df0fce\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6af1fac31aa1e798f132d39cfd771787464f9d6d42694aca750b4cda651c2d46\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, portalocker, dill, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.0.1\n","    Uninstalling pymongo-4.0.1:\n","      Successfully uninstalled pymongo-4.0.1\n","Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.6 portalocker-2.3.2 proto-plus-1.19.8 protobuf-3.19.3 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-6.0 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"]},{"output_type":"stream","name":"stderr","text":["  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"]}]},{"cell_type":"code","source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz\n","!tar -xf centernet_hg104_512x512_coco17_tpu-8.tar.gz"],"metadata":{"id":"1JD8vaf-6vYd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643033200798,"user_tz":-180,"elapsed":54554,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"a707d9c3-54d2-480b-ba1a-c9131a328ad2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-24 14:05:47--  http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.135.128, 2607:f8b0:400e:c01::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.135.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1426099846 (1.3G) [application/x-tar]\n","Saving to: ‘centernet_hg104_512x512_coco17_tpu-8.tar.gz’\n","\n","centernet_hg104_512 100%[===================>]   1.33G  65.7MB/s    in 20s     \n","\n","2022-01-24 14:06:07 (66.5 MB/s) - ‘centernet_hg104_512x512_coco17_tpu-8.tar.gz’ saved [1426099846/1426099846]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"metadata":{"id":"msFi-RHHDpj9","executionInfo":{"status":"ok","timestamp":1643033200803,"user_tz":-180,"elapsed":15,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#Old version\n"],"metadata":{"id":"MssBAzaADqF_"}},{"cell_type":"markdown","source":[" **Inspiration** : https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/plot_object_detection_saved_model.html#sphx-glr-auto-examples-plot-object-detection-saved-model-py"],"metadata":{"id":"0EnczHbNIieP"}},{"cell_type":"code","source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import pathlib\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n"],"metadata":{"id":"LliN_2mQbRKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download and extract model\n","def download_model(model_name, model_date):\n","    base_url = 'http://download.tensorflow.org/models/object_detection/tf2/'\n","    model_file = model_name + '.tar.gz'\n","    model_dir = tf.keras.utils.get_file(fname=model_name,\n","                                        origin=base_url + model_date + '/' + model_file,\n","                                        untar=True)\n","    return str(model_dir)\n","\n","MODEL_DATE = '20200711'\n","MODEL_NAME = 'centernet_hg104_1024x1024_coco17_tpu-32'\n","PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)"],"metadata":{"id":"4SUQSgk2QAbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Download labels file\n","def download_labels(filename):\n","    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n","    label_dir = tf.keras.utils.get_file(fname=filename,\n","                                        origin=base_url + filename,\n","                                        untar=False)\n","    label_dir = pathlib.Path(label_dir)\n","    return str(label_dir)\n","\n","LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n","PATH_TO_LABELS = download_labels(LABEL_FILENAME)"],"metadata":{"id":"xJ8HudWbXC8d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Run on a test data "],"metadata":{"id":"Ahfgsso_A4U-"}},{"cell_type":"code","source":["\n","PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# Load saved model and build the detection function\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))"],"metadata":{"id":"o-dMWBfvYOU4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642774927512,"user_tz":-180,"elapsed":82130,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"98f497ee-910e-42ba-a3a5-40b97dd94069"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model..."]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53414) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35984) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38889) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54075) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_73_layer_call_and_return_conditional_losses_200673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47992) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38228) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45106) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41330) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45322) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48208) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49314) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43555) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46428) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48437) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23932) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_72_layer_call_and_return_conditional_losses_64920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34179) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37122) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32577) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_73_layer_call_and_return_conditional_losses_65063) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33734) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30810) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42436) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49562) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45767) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21046) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45551) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46657) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_encoder_decoder_block_layer_call_and_return_conditional_losses_60787) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27250) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27924) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51825) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47318) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_encoder_decoder_block_5_layer_call_and_return_conditional_losses_71112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_36_layer_call_and_return_conditional_losses_64774) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_encoder_decoder_block_layer_call_and_return_conditional_losses_188192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29030) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_201940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_input_downsample_block_layer_call_and_return_conditional_losses_181590) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_201700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43987) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_19495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29475) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23042) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_201820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22381) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31255) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53166) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52257) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42665) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24148) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49098) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36893) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40885) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39563) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30365) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29691) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_71_layer_call_and_return_conditional_losses_200410) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_19279) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31471) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22152) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_20601) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_hourglass_network_layer_call_and_return_conditional_losses_155730) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54304) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_center_net_hourglass_feature_extractor_layer_call_and_return_conditional_losses_136884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39995) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39779) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52721) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_36_layer_call_and_return_conditional_losses_200274) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33041) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25928) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21707) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_20385) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28585) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33950) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45983) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218860) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46212) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25254) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_19050) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_20830) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33270) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41991) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_72_layer_call_and_return_conditional_losses_200543) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46873) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52505) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43326) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29920) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38673) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39334) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27695) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_input_downsample_block_layer_call_and_return_conditional_losses_54872) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_20156) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44661) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28369) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_hourglass_network_layer_call_and_return_conditional_losses_174576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_encoder_decoder_block_5_layer_call_and_return_conditional_losses_197040) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_hourglass_network_layer_call_and_return_conditional_losses_93754) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25699) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37567) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32361) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34859) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218500) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51596) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25483) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32145) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36677) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53643) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206740) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_201580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23258) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47763) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48882) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33486) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_201460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27479) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203380) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_center_net_hourglass_feature_extractor_layer_call_and_return_conditional_losses_118038) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30581) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_residual_block_69_layer_call_and_return_conditional_losses_65298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34395) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26818) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42220) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_19711) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51132) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48653) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26589) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27034) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203020) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35520) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211420) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21262) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_19940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35768) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_204100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44877) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_201340) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40440) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43110) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219460) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216700) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26144) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209620) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31026) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28140) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_residual_block_69_layer_call_and_return_conditional_losses_200881) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217300) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213940) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208060) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22826) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37338) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23487) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47547) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35088) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29246) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219820) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40224) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203980) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37783) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24377) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_convolutional_block_71_layer_call_and_return_conditional_losses_75099) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210580) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_202900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_203260) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"]},{"output_type":"stream","name":"stdout","text":["Done! Took 82.10095262527466 seconds\n"]}]},{"cell_type":"code","source":["detect_fn.__dict__.keys()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVvHCK6JA161","executionInfo":{"status":"ok","timestamp":1642774931482,"user_tz":-180,"elapsed":236,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"0aee2a7c-c8ae-4fd0-e8b0-1f9f3e24de9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['_self_setattr_tracking', '_self_unconditional_checkpoint_dependencies', '_self_unconditional_dependency_names', '_self_unconditional_deferred_dependencies', '_self_update_uid', '_self_name_based_restores', '_self_saveable_object_factories', '_model', 'signatures', '__call__', 'graph_debug_info', 'tensorflow_version', 'tensorflow_git_version'])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["for k,v in detect_fn.__dict__.items(): print(k, type(v))\n","print('*****')\n","for k,v in detect_fn._model.__dict__.items(): print(k, type(v))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbA2qupnBHsl","executionInfo":{"status":"ok","timestamp":1642775075701,"user_tz":-180,"elapsed":225,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"c412ea13-c273-472f-8f46-ddac7ef1dd0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["_self_setattr_tracking <class 'bool'>\n","_self_unconditional_checkpoint_dependencies <class 'list'>\n","_self_unconditional_dependency_names <class 'dict'>\n","_self_unconditional_deferred_dependencies <class 'dict'>\n","_self_update_uid <class 'int'>\n","_self_name_based_restores <class 'set'>\n","_self_saveable_object_factories <class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>\n","_model <class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n","signatures <class 'tensorflow.python.saved_model.signature_serialization._SignatureMap'>\n","__call__ <class 'tensorflow.python.saved_model.function_deserialization.RestoredFunction'>\n","graph_debug_info <class 'tensorflow.core.protobuf.graph_debug_info_pb2.GraphDebugInfo'>\n","tensorflow_version <class 'str'>\n","tensorflow_git_version <class 'str'>\n","*****\n","_self_setattr_tracking <class 'bool'>\n","_self_unconditional_checkpoint_dependencies <class 'list'>\n","_self_unconditional_dependency_names <class 'dict'>\n","_self_unconditional_deferred_dependencies <class 'dict'>\n","_self_update_uid <class 'int'>\n","_self_name_based_restores <class 'set'>\n","_self_saveable_object_factories <class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>\n","_feature_extractor <class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n","_prediction_head_dict <class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>\n","_target_assigner_dict <class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>\n","_batched_prediction_tensor_names <class 'tensorflow.python.training.tracking.data_structures.ListWrapper'>\n","_groundtruth_lists <class 'tensorflow.python.training.tracking.data_structures._DictWrapper'>\n","keras_api <class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n"]}]},{"cell_type":"code","source":["category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","                                                                    use_display_name=True)"],"metadata":{"id":"3JcW94tGZd3y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","%matplotlib inline\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","\n","    Args:\n","      path: the file path to the image\n","\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))\n","\n","IMAGE_PATHS = os.listdir('WritingsDetector/WritingsDataset/WritingN/')\n","for image_name in IMAGE_PATHS:\n","    image_path = 'WritingsDetector/WritingsDataset/WritingN/' + image_name\n","    print('Running inference for {}... '.format(image_path), end='')\n","\n","    image_np = load_image_into_numpy_array(image_path)\n","\n","    # Things to try:\n","    # Flip horizontally\n","    # image_np = np.fliplr(image_np).copy()\n","\n","    # Convert image to grayscale\n","    # image_np = np.tile(\n","    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","\n","    # input_tensor = np.expand_dims(image_np, 0)\n","    detections = detect_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                   for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.30,\n","          agnostic_mode=False)\n","\n","    plt.figure()\n","    plt.imshow(image_np_with_detections)\n","    print('Done')\n","    plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qvFgdElx8wKz3czdshBsvr5SBx2HaH_d"},"id":"KqmdhvFQXW4B","executionInfo":{"status":"error","timestamp":1642437848564,"user_tz":-180,"elapsed":106423,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"375b7c77-78d3-4edd-b702-e2c9036aaa9b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Start training\n"],"metadata":{"id":"Sl87AUFZ8KkV"}},{"cell_type":"code","source":["import numpy as np\n","import glob\n","import os\n","import pandas as pd\n","import math   \n","from decord import VideoReader\n","from decord import cpu, gpu\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import gc\n","import tensorflow.keras.backend as K"],"metadata":{"id":"FGd_BjSb7xfa","executionInfo":{"status":"ok","timestamp":1643033203324,"user_tz":-180,"elapsed":2531,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def get_keypoint_tuples(eval_config):\n","  \"\"\"Return a tuple list of keypoint edges from the eval config.\n","  \n","  Args:\n","    eval_config: an eval config containing the keypoint edges\n","  \n","  Returns:\n","    a list of edge tuples, each in the format (start, end)\n","  \"\"\"\n","  tuple_list = []\n","  kp_list = eval_config.keypoint_edge\n","  for edge in kp_list:\n","    tuple_list.append((edge.start, edge.end))\n","  return tuple_list"],"metadata":{"id":"hntGGksA6mvr","executionInfo":{"status":"ok","timestamp":1643033203326,"user_tz":-180,"elapsed":14,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def load_label_binary(df, id):\n","    ids = df['ID_Frame']\n","    genres_str = (df.loc[ids == id])['Genres_subset']\n","def load_name(csv_path,id):\n","    df= pd.read_csv(csv_path)\n","    ids = df['ID_Frame']\n","    return (df.loc[ids == id])['Name'].astype(str)\n","def load_label(df,id):\n","    ids = df['ID_Frame']\n","    genres_str = (df.loc[ids == id])['Genres'].values.tolist()\n","    if genres_str:\n","        genres = genres_str[0].strip('\\\"[\\'\\'\\']\\\"').split('|')\n","        return genres\n","    else:\n","        return []\n","def load_label2(df,id):\n","    ids = df['ID_Frame']\n","    genres_str = (df.loc[ids == id])['Genres_subset'].values.tolist()\n","    if genres_str:\n","        genres = genres_str[0].strip('\\\"[\\'\\'\\']\\\"').split('|')\n","        return genres\n","    else:\n","        return []\n","\n","def load_frames_list(df,id):\n","\n","    ids = df['ID_Frame']\n","    if  (df.loc[ids == id])['Number_Scenes'].values.astype(int)>0:\n","        return (df.loc[ids == id])['Cut_Points'].apply(lambda x:   [list(map(int, a.split(\",\"))) for a in  np.array(x.replace(' ','').strip(']][[').split(\"],[\"))]).tolist()[0]\n","\n","    else:\n","        return []\n","\n","df = pd.read_csv( 'CsvFiles/3class_trial.csv')\n","df[\"Genres_subset\"]=df[\"Genres_subset\"].apply(lambda x:x.strip('][').replace('\\'','').replace(' ','').split(\",\"))\n","\n","df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n","print(df)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZWu8LhW7394","executionInfo":{"status":"ok","timestamp":1643033203760,"user_tz":-180,"elapsed":441,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"a73b692e-c0b1-4c60-cd3f-9cf69a60c2ae"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["     ID_Frame  ... Genres_subset\n","0        6377  ...      [Comedy]\n","1        8651  ...      [Comedy]\n","2        1270  ...      [Comedy]\n","3        2246  ...      [Comedy]\n","4        1013  ...     [Romance]\n","..        ...  ...           ...\n","383      5064  ...     [Romance]\n","384      3973  ...      [Horror]\n","385      5724  ...      [Horror]\n","386      2363  ...      [Horror]\n","387      1136  ...      [Comedy]\n","\n","[388 rows x 6 columns]\n"]}]},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"metadata":{"id":"3FUjWAWZ7Uj1","executionInfo":{"status":"ok","timestamp":1643033204209,"user_tz":-180,"elapsed":453,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#構成情報ファイルのパス。リポジトリにConfigファイルの揃ったフォルダがあるけど、微妙にモデル名が省略されていたりするので、ダウンロードしたものの方が確実？\n","pipeline_config = \"./centernet_hg104_512x512_coco17_tpu-8/pipeline.config\"\n","#チェックポイントのパス \n","model_dir = \"./centernet_hg104_512x512_coco17_tpu-8/checkpoint\"\n","\n","#モデル構成情報読み込み\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","\n","#読み込んだ構成情報でモデルをビルド\n","detection_model = model_builder.build(\n","      model_config=model_config, is_training=False)\n","\n","#チェックポイントから重みを復元\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z1wFjbV77QSJ","executionInfo":{"status":"ok","timestamp":1643033208157,"user_tz":-180,"elapsed":3952,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"3dc27743-1274-4ba5-fc25-0b044f5a5278"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3b08c859d0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["'from tensorflow.keras.utils import Sequence'\n","\n","\n","class DataGenerator(tf.keras.utils.Sequence):\n","    '''\n","        csv_file: CSV file should include cut points, number of scenes, genres, id frame. \n","        data_folder : give folder that the data -videos / trailers - is located \n","        batch size : give batch size.\n","        x_label : video_ids\n","        y_label : genres / labels column\n","        main_genre : all genre / labels you want to train from \n","        dim : dimension of the frames \n","            dim should be four dimensional. (give without the RGB CHANNEL for ex. (100,100).)\n","        frame_rate :  how many frames we select from each of the scenes. Give a even number (!)\n","        x_label : video ids column name in the dataframe. \n","        y_label : genre labels column name in the dataframe\n","        cut_points_column : list of cutpoints column name in the dataframe (For example  Scenes)\n","        size_of_cut_list_column: number of sceness of that video. (For example: Number Scenes)\n","        shuffle : if shuffle (True or false.)\n","        \n","        \n","    '''\n","    def __init__(self,data_folder,batch_size,n_classes,cut_points_column,frame_rate,csv_file,x_label,y_label,main_genre,size_of_cut_list_column, \n","                 preprocess = False, shuffle = True,dim = (100,100)):#Initializing the values\n","        self.dim = dim\n","        self.main_genre = main_genre\n","        self.data_folder = data_folder\n","        self.frame_rate = frame_rate\n","        self.x_label = x_label\n","        self.y_label = y_label\n","        self.cut_points_column = cut_points_column\n","        self.stats = csv_file\n","        self.video_ids = self.stats[self.x_label].tolist()\n","        self.video_ids = [str(data_folder+'/'+str(a)+\".mp4\") for a in self.video_ids]\n","        \n","        #No more needed snce we have the function called df_to_list  \n","        # automatically have the struct for the video_id , frame_begin, frame_end for each of the scenes.\n","        # self.cut_points =self.stats[cut_points_column].apply(lambda x:[list(map(int, a.split(\",\"))) for a in  np.array(x.strip(']][[').split(\"], [\"))]).tolist()\n","        self.size_of_cut_list_column = size_of_cut_list_column\n","        self.genres=self.stats[self.y_label].apply(lambda x:x.strip('][').replace('\\\"','\\'').replace(' ','').replace('\\'','').split(\",\"))\n","\n","        self.batch_size = int(batch_size)\n","        #Data is in the format : (video_id , frame_begin, frame_end)  for each of the scenes. \n","        #Size should be total number of the frames.\n","        self.n_classes = n_classes\n","        self.preprocess = preprocess\n","        \n","        \n","        self.shuffle = shuffle \n","        self.dic = {x: i for i,x in enumerate(self.main_genre)}\n","        self.data,self.labels=  self.df_to_dictionary(csv_file,self.x_label, self.size_of_cut_list_column)\n","        self.indexes = np.arange( len(self.data))\n","        self.max = self.__len__()\n","        # this integer encoding is purely based on position, you can do this in other ways\n","        print(\"Found # trailers: \",len(self.stats[x_label].tolist()))\n","        print(\"Found data size: \",len(self.data))\n","        print(\"Found the labels\", self.y_label)\n","        print(\"given the data folder\", self.data_folder)\n","        #print(self.cut_points[1][0])\n","        \n","        self.max = self.__len__()\n","        self.on_epoch_end()\n","\n","\n","    # Convert dataframe to list so we dont search everytime. \n","    # Format is video_id, scene_start_frame, scene_end_frame\n","    def df_to_dictionary(self, csv_file, x_column_name, size_column_name, shuffle = False):\n","        video_ids =  csv_file[x_column_name].tolist()\n","        total_number_scenes =  int(sum(csv_file[size_column_name].tolist()))\n","\n","        list_of_scenes = np.empty(shape=(total_number_scenes,3),dtype=np.int)\n","        genres = np.empty(shape = (total_number_scenes, self.n_classes),dtype=np.int)\n","        index = 0\n","        for i, v_id in enumerate(video_ids):\n","            scenes = load_frames_list(csv_file,v_id)\n","\n","            for j, scene in enumerate(scenes):\n","\n","                list_of_scenes[index] = [v_id, scene[0],scene[1] ]\n","                labels = load_label2(self.stats,v_id)\n","\n","                genres[index,:] = [int(k in labels) for k,v in self.dic.items()]\n","                \n","                index = index+1\n","        \n","        return list_of_scenes,genres\n","\n","\n","    #Preprocess with resnet50 features.\n","    def preprocess_data(self,X):\n","        X_p = [tf.keras.applications.inception_resnet_v2.preprocess_input(x) for x in X]\n","        return np.asarray(X_p)\n","\n","    def get_step_size(self):\n","        return (len(self.data) // self.batch_size)\n","\n","    def on_epoch_end(self,batch = None, logs=None):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.indexes))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","        # Run garbage collector. Avoid memory leaks.\n","        # print(\"gc runned.\")\n","        gc.enable()\n","        gc.collect()\n","        K.clear_session()\n","\n","    def __len__(self):\n","        return math.ceil(len(self.data) / self.batch_size)\n","\n","    def load_label(self,one_hot):\n","        return [list(self.dic)[i] for i,k in enumerate(one_hot) if one_hot[i]==1]\n","\n","    def __getitem__(self, index):\n","        #print(\"get item is called\", index)\n","        #Generate batch at position 'index' \n","        batches = self.indexes[index*self.batch_size:(index+1)*self.batch_size] \n","        #\n","        #Generate batch \n","        X,y = self.__data_generation(batches)\n","        #print(\"x shape : \", X.shape,\" y shape\", y.shape)\n","          \n","        return X,y\n","    def __data_generation(self,list_IDs): \n","        X = np.empty(shape=(self.batch_size,self.frame_rate,self.dim[0],self.dim[1],3),dtype=np.int)\n","        y = np.empty(shape=(self.batch_size,len(self.main_genre)))\n","        #Iterating through each#sequence of frames\n","        for i,ID in enumerate(list_IDs): \n","            video_id,cut_b,cut_e =self.data[ID]\n","            label = self.labels[ID]\n","\n","            frames = self._frames_extraction_with_cut_in_middle(self.data_folder+'/'+video_id.astype(str)+\".mp4\", self.frame_rate,self.dim,[cut_b,cut_e])      \n","\n","            X[i] = frames\n","           \n","            y[i] = label\n","        if self.preprocess:\n","            X =self.preprocess_data(np.asarray(X))\n","        else:\n","            X = np.asarray(X)\n","        #return np.append(X_preprocessed,np.asarray(X), axis=1),np.asarray(y)\n","        return X, np.asarray(y)\n","    def _frames_extraction_with_cut_in_middle(self,video_path,frame_rate,img_dim,cut):\n","        # Empty List declared to store video frames\n","        frames_list = np.empty(shape=(frame_rate,img_dim[0],img_dim[1],3),dtype = np.int)\n","        image_height,image_width = img_dim\n","        # Reading the Video File Using the VideoCapture\n","        vr = VideoReader(video_path, ctx=cpu(0),width=image_width, height=image_height)\n","        # a file like object works as well, for in-memory decoding\n","        length = int(len(vr))\n","\n","        start,end = cut\n","        mid = int((end -start) /2)\n","        n_start = (mid+start) - int(frame_rate * frame_rate/2)\n","        n_end =  (mid+start) +int(frame_rate * frame_rate/2)\n","        rate = int(math.floor((n_end - n_start)/frame_rate))        \n","        #print(\"start \" , start , \", end \", end, \" , mid \", mid ,\", n_start \",n_start ,\", n_end \", n_end )\n","        #print(rate)\n","        if rate < 1 : \n","            print(\"problem.\")\n","            rate=1\n","        else:\n","\n","            valid_nums = filter(lambda x: x % rate == 0, range(n_start, n_end))\n","            filtered_numbers = list(valid_nums)\n","            frames_list = vr.get_batch(filtered_numbers).asnumpy()\n","  \n","    \n","        # returning the frames list \n","        return frames_list\n","   "],"metadata":{"id":"sJ6Uvzfq7--G","executionInfo":{"status":"ok","timestamp":1643033627853,"user_tz":-180,"elapsed":870,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","\n","main_genre = ['Comedy','Horror','Romance']\n","df_train_ready = pd.read_csv(\"CsvFiles/3class_trial.csv\")\n","\n","# df = get_equal_subsets(main_genre,df,df_out=df_out_name)\n","\n","input_dim = (224,224)\n","BATCH_SIZE = 32\n","frame_rate =4\n","preprocess = False\n","\n","\n","num_classes = len(main_genre)\n","params = {\n","    'batch_size':BATCH_SIZE,\n","    'dim':input_dim,\n","    'n_classes':num_classes,\n","    'shuffle':True,\n","    'csv_file':df_train_ready[:300],\n","    'main_genre':main_genre ,\n","    'x_label' : 'ID_Frame',\n","    'y_label': 'Genres_subset',\n","    'cut_points_column' :'Cut_Points',\n","    'size_of_cut_list_column' : 'Number_Scenes',\n","    'preprocess' : preprocess,\n","    'frame_rate': frame_rate}\n","train_generator = DataGenerator(\"Data\",**params)\n","num_classes = len(main_genre)\n","params = {\n","    'batch_size':BATCH_SIZE,\n","    'dim':input_dim,\n","    'n_classes':num_classes,\n","    'shuffle':True,\n","    'csv_file':df_train_ready[300:],\n","    'main_genre':main_genre ,\n","    'x_label' : 'ID_Frame',\n","    'y_label': 'Genres_subset',\n","    'cut_points_column' :'Cut_Points',\n","    'preprocess' : preprocess,\n","    'size_of_cut_list_column' : 'Number_Scenes',\n","    'frame_rate': frame_rate}\n","valid_generator = DataGenerator(\"Data\",**params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHk0xjCc8Djt","executionInfo":{"status":"ok","timestamp":1643033635198,"user_tz":-180,"elapsed":6042,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"f635af0d-9b56-4613-dcbd-deddaeb72002"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found # trailers:  300\n","Found data size:  6126\n","Found the labels Genres_subset\n","given the data folder Data\n","Found # trailers:  88\n","Found data size:  1620\n","Found the labels Genres_subset\n","given the data folder Data\n"]}]},{"cell_type":"code","source":["import tensorflow as tf  \n","from object_detection.utils import label_map_util \n","from object_detection.utils import config_util \n","from object_detection.utils import visualization_utils as viz_utils \n","\n","from object_detection.builders import model_builder  \n","\n","\n","%matplotlib inline\n","# The path to the pipeline config.\n","pipeline_config = \"./centernet_hg104_512x512_coco17_tpu-8/pipeline.config\" \n","# The to the checkpoint.\n","model_dir = \"./centernet_hg104_512x512_coco17_tpu-8/checkpoint\"\n","# Reading the model configurations.\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config) \n","\n","model_config = configs['model']# Build the model with the configurations read.\n","detection_model = model_builder.build(model_config=model_config, is_training=False)\n","# Restore the weights from the checkpoint.\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model) \n","ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14pGxY5HlzNw","executionInfo":{"status":"ok","timestamp":1643033635620,"user_tz":-180,"elapsed":425,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"a78f68a3-a165-472d-9344-4e96650288e1"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3b06e8e350>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["label_map_path = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"metadata":{"id":"N_S0kFPWna9J","executionInfo":{"status":"ok","timestamp":1643033635622,"user_tz":-180,"elapsed":7,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n","    if type(ims[0]) is np.ndarray:\n","        ims = np.array(ims)\n","        if (ims.shape[-1] != 3):\n","            ims = ims.transpose((0,2,3,1))\n","    f = plt.figure(figsize=figsize)\n","    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n","    for i in range(len(ims)):\n","        sp = f.add_subplot(rows, cols, i+1)\n","        sp.axis('Off')\n","        if titles is not None:\n","            sp.set_title(titles[i], fontsize=6)\n","        plt.imshow(ims[i], aspect='auto', interpolation=None if interp else 'none')\n","for j in range(3,4):\n","    res = train_generator.__getitem__(j)\n","    train_generator.on_epoch_end()\n","    \n","    \n","    for k,imgs in enumerate(res[0]):\n","      titles = [train_generator.load_label(res[1][k]) for k in range(BATCH_SIZE)]\n","      plot_imgs = []\n","      for img in imgs:\n","        input_tensor = tf.convert_to_tensor(\n","            np.expand_dims(img, 0), dtype=tf.float32)\n","        image, shapes = detection_model.preprocess(input_tensor)\n","        prediction_dict = detection_model.predict(image, shapes)\n","\n","        detections = detection_model.postprocess(prediction_dict, shapes)\n","        #heatmap = get_heatmap(prediction_dict, 'person')\n","        #resized_heatmap_unpadded = unpad_heatmap(heatmap, img)\n","        #Use keypoints if available in detections\n","        label_id_offset = 1\n","        image_np_with_detections = img.copy()\n","##\n","        keypoints, keypoint_scores = None, None\n","        if 'detection_keypoints' in detections:\n","            keypoints = detections['detection_keypoints'][0].numpy()\n","            keypoint_scores = detections['detection_keypoint_scores'][0].numpy()\n","##\n","        viz_utils.visualize_boxes_and_labels_on_image_array(image_np_with_detections,\n","            detections['detection_boxes'][0].numpy(),\n","            (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n","            detections['detection_scores'][0].numpy(),\n","            category_index,\n","            use_normalized_coordinates=True,\n","            max_boxes_to_draw=200,\n","            min_score_thresh=.30,\n","            agnostic_mode=False,\n","            keypoints=keypoints,\n","            keypoint_scores=keypoint_scores,\n","            keypoint_edges=get_keypoint_tuples(configs['eval_config']))\n","        plot_imgs.append(image_np_with_detections)\n","      plots(plot_imgs,titles=[titles[k]]*frame_rate,rows = 1,figsize=(12,2))\n","        #print(titles)\n","        #print(\"imgs.shape is : \", imgs.shape)\n","        #print(\"labels.shape is : \", labels.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1A_g-BO40hCVH-Q9I2Duw_FNJo1S56173"},"id":"oKuwAOzlqxSH","executionInfo":{"status":"ok","timestamp":1643033789062,"user_tz":-180,"elapsed":69542,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"7eb2f333-d7bc-4ac0-a4db-b901a88563ca"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["detection_model = model_builder.build(model_config=model_config, is_training=False)\n","pretrained_model.layers[0].layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4-yQHKQ_3mm","executionInfo":{"status":"ok","timestamp":1642964893933,"user_tz":-180,"elapsed":1588,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"87718061-7498-41d2-fbcb-97df928bc2f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<object_detection.models.keras_models.hourglass_network.InputDownsampleBlock at 0x7f460f3fc590>,\n"," <object_detection.models.keras_models.hourglass_network.EncoderDecoderBlock at 0x7f460f0d57d0>,\n"," <object_detection.models.keras_models.hourglass_network.EncoderDecoderBlock at 0x7f460ee8b7d0>,\n"," <object_detection.models.keras_models.hourglass_network.ConvolutionalBlock at 0x7f460ef03650>,\n"," <object_detection.models.keras_models.hourglass_network.ConvolutionalBlock at 0x7f4613ddffd0>,\n"," <object_detection.models.keras_models.hourglass_network.ConvolutionalBlock at 0x7f46139de450>,\n"," <object_detection.models.keras_models.hourglass_network.ConvolutionalBlock at 0x7f4613a61590>,\n"," <object_detection.models.keras_models.hourglass_network.ResidualBlock at 0x7f4613f96c50>,\n"," <keras.layers.advanced_activations.ReLU at 0x7f4613f9f090>]"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["\n","def get_heatmap(predictions_dict, class_name):\n","  \"\"\"Grabs class center logits and apply inverse logit transform.\n","\n","  Args:\n","    predictions_dict: dictionary of tensors containing a `object_center`\n","      field of shape [1, heatmap_width, heatmap_height, num_classes]\n","    class_name: string name of category (e.g., `horse`)\n","\n","  Returns:\n","    heatmap: 2d Tensor heatmap representing heatmap of centers for a given class\n","      (For CenterNet, this is 128x128 or 256x256) with values in [0,1]\n","  \"\"\"\n","  class_index = label_map_dict[class_name]\n","  class_center_logits = predictions_dict['object_center'][0]\n","  class_center_logits = class_center_logits[0][\n","    :, :, class_index - label_id_offset]\n","  heatmap = tf.exp(class_center_logits) / (tf.exp(class_center_logits) + 1)\n","  return heatmap\n","\n","def unpad_heatmap(heatmap, image_np):\n","  \"\"\"Reshapes/unpads heatmap appropriately.\n","\n","  Reshapes/unpads heatmap appropriately to match image_np.\n","\n","  Args:\n","    heatmap: Output of `get_heatmap`, a 2d Tensor\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3).  Note\n","      that due to padding, the relationship between img_height and img_width\n","      might not be a simple scaling.\n","\n","  Returns:\n","    resized_heatmap_unpadded: a resized heatmap (2d Tensor) that is the same\n","      size as `image_np`\n","  \"\"\"\n","  heatmap = tf.tile(tf.expand_dims(heatmap, 2), [1, 1, 3]) * 255\n","  pre_strided_size = detection_model._stride * heatmap.shape[0]\n","  resized_heatmap = tf.image.resize(\n","      heatmap, [pre_strided_size, pre_strided_size],\n","      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","  resized_heatmap_unpadded = tf.slice(resized_heatmap, begin=[0,0,0], size=shapes)\n","  return tf.image.resize(\n","      resized_heatmap_unpadded,\n","      [image_np.shape[0], image_np.shape[1]],\n","      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)[:,:,0]\n"],"metadata":{"id":"1wuBCosmrWig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import regularizers\n","import keras\n","\n","from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from keras.layers import Dense, LSTM, Flatten, TimeDistributed, Conv2D, Dropout,GRU,AveragePooling2D\\\n",",BatchNormalization,MaxPool2D,GlobalMaxPool2D,InputLayer\n","from keras import Sequential\n","from keras.applications.resnet import ResNet\n","from tensorflow.keras import Input\n","detection_model = model_builder.build(model_config=model_config, is_training=False)\n","pretrained_model = detection_model._feature_extractor\n","\n","regu = regularizers.l1_l2(l1=1e-5, l2=1e-4)\n","momentum = .9\n","\n","\n","#for layer in pretrained_model.layers[0].layers[:-4]:\n","#    layer.trainable = False# create a Sequential model\n","model = Sequential()\n","model.add(TimeDistributed(pretrained_model.layers[0]))\n","\n","model.add(Dropout(.3))\n","\n","model.add(Dense(num_classes, activation='sigmoid'))\n"],"metadata":{"id":"4wqQMwDD8H0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow\n","optimizer = tensorflow.keras.optimizers.Adam(0.0001)\n","model.compile(\n","    optimizer,\n","    loss= ['categorical_crossentropy'],\n","    metrics=['acc']\n",")"],"metadata":{"id":"_my_02olPUYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import LambdaCallback\n","def fit_model(model, train_generator, valid_generator):\n","\n","    try:\n","\n","\n","        print('Start fitting model')\n","        checkpointer = keras.callbacks.ModelCheckpoint(\n","                          'chkp2/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n","                          verbose=1)\n","        model.fit(\n","            train_generator,\n","            steps_per_epoch=train_generator.__len__(),\n","            epochs=20,\n","            validation_data=valid_generator,\n","            validation_steps=valid_generator.__len__(),\n","            verbose=1,\n","            callbacks=[\n","                       LambdaCallback(on_epoch_end=train_generator.on_epoch_end),\n","                       LambdaCallback(on_epoch_end=valid_generator.on_epoch_end) ,\n","                       keras.callbacks.ReduceLROnPlateau(verbose=1),\n","                       ],\n","            use_multiprocessing = True\n","\n","        )\n","        #model.save_weights('ConvLSTM.h5')\n","    except KeyboardInterrupt:\n","        print('Training time:')\n","\n","        for k, v in locals().items():\n","            #if type(v) is Variable or type(v) is tensorflow.Tensor:\n","            print(\"{0}: {1}\".format(k, v))   \n","\n","fit_model(model, train_generator, valid_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"9xyvl0CTF9KZ","executionInfo":{"status":"error","timestamp":1642965063249,"user_tz":-180,"elapsed":9847,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"ac8aeba2-9157-4a92-b857-3e9ea0319c46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start fitting model\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-121-1446e8a94834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-121-1446e8a94834>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, train_generator, valid_generator)\u001b[0m\n\u001b[1;32m     21\u001b[0m                        \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                        ],\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hourglasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mhourglass_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhourglass_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhourglass_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"encoder_decoder_block_460\" (type EncoderDecoderBlock).\n\nin user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 340, in call  *\n        inner_block_outputs = _apply_blocks(\n    File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 268, in _apply_blocks  *\n        net = block(net)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"encoder_decoder_block_461\" (type EncoderDecoderBlock).\n    \n    in user code:\n    \n        File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 340, in call  *\n            inner_block_outputs = _apply_blocks(\n        File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 268, in _apply_blocks  *\n            net = block(net)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"encoder_decoder_block_462\" (type EncoderDecoderBlock).\n        \n        in user code:\n        \n            File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 340, in call  *\n                inner_block_outputs = _apply_blocks(\n            File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 268, in _apply_blocks  *\n                net = block(net)\n            File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            ValueError: Exception encountered when calling layer \"encoder_decoder_block_463\" (type EncoderDecoderBlock).\n            \n            in user code:\n            \n                File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/keras_models/hourglass_network.py\", line 347, in call  *\n                    return self.merge_features([encoded_outputs, upsampled_outputs])\n                File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\", line 79, in _compute_elemwise_op_output_shape\n                    'Inputs have incompatible shapes. '\n            \n                ValueError: Inputs have incompatible shapes. Received shapes (7, 7, 384) and (8, 8, 384)\n            \n            \n            Call arguments received:\n              • inputs=tf.Tensor(shape=(32, 7, 7, 384), dtype=float32)\n        \n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(32, 14, 14, 384), dtype=float32)\n    \n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(32, 28, 28, 256), dtype=float32)\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32, 56, 56, 256), dtype=float32)"]}]},{"cell_type":"markdown","source":["# Another approach\n"],"metadata":{"id":"XeqHO_XTJ9hh"}},{"cell_type":"code","source":["!pip install gluoncv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbnWKmRdGs67","executionInfo":{"status":"ok","timestamp":1642960987283,"user_tz":-180,"elapsed":8130,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"08d88d77-565b-484b-eeb7-8bb74893d078"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gluoncv\n","  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 952 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.2 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (6.0)\n","Collecting autocfg\n","  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.3.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.27.1)\n","Collecting yacs\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.1.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (3.0.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.10.8)\n","Installing collected packages: yacs, autocfg, gluoncv\n","Successfully installed autocfg-0.0.8 gluoncv-0.10.4.post4 yacs-0.1.8\n"]}]},{"cell_type":"code","source":["!pip install mxnet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0mQs4tjGyV5","executionInfo":{"status":"ok","timestamp":1642961037916,"user_tz":-180,"elapsed":11817,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"4e44044b-e5e4-434c-b080-876556b637b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n","\u001b[K     |████████████████████████████████| 47.3 MB 73 kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.0\n"]}]},{"cell_type":"code","source":["from gluoncv import model_zoo, data, utils\n","from matplotlib import pyplot as plt"],"metadata":{"id":"DMWeQjodGq4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = model_zoo.get_model('yolo3_darknet53_voc', pretrained=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-KK0BrxGzle","executionInfo":{"status":"ok","timestamp":1642961139688,"user_tz":-180,"elapsed":10661,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"38f578e8-442b-4d51-e6d1-cb99642c20d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading /root/.mxnet/models/yolo3_darknet53_voc-f5ece5ce.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/yolo3_darknet53_voc-f5ece5ce.zip...\n"]},{"output_type":"stream","name":"stderr","text":["223070KB [00:05, 39860.91KB/s]\n"]}]},{"cell_type":"code","source":["print(net.__dict__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tunb62JrH2bb","executionInfo":{"status":"ok","timestamp":1642961292352,"user_tz":-180,"elapsed":273,"user":{"displayName":"Irmak Türköz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBKugg3AwKzSGhYpyiD5vdS8SCH9E9MnMIsAWQ=s64","userId":"13125594217489508006"}},"outputId":"8be74371-6dc1-42ed-e682-9defb3bc7394"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'_empty_prefix': False, '_prefix': 'yolov30_', '_params': yolov30_ (\n","\n","), '_name': 'yolov30', '_scope': <mxnet.gluon.block._BlockScope object at 0x7f461a1943d0>, '_children': OrderedDict([('_target_generator', YOLOV3TargetMerger(\n","  (_dynamic_target): YOLOV3DynamicTargetGeneratorSimple(\n","    (_batch_iou): BBoxBatchIOU(\n","      (_pre): BBoxSplit(\n","      \n","      )\n","    )\n","  )\n",")), ('_loss', YOLOV3Loss(batch_axis=0, w=None)), ('stages', HybridSequential(\n","  (0): HybridSequential(\n","    (0): HybridSequential(\n","      (0): Conv2D(3 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (1): HybridSequential(\n","      (0): Conv2D(32 -> 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (2): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(64 -> 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(32 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (3): HybridSequential(\n","      (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (4): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(128 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (5): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(128 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (6): HybridSequential(\n","      (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (7): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (8): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (9): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (10): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (11): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (12): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (13): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (14): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","  )\n","  (1): HybridSequential(\n","    (0): HybridSequential(\n","      (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (1): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (2): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (3): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (4): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (5): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (6): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (7): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (8): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","  )\n","  (2): HybridSequential(\n","    (0): HybridSequential(\n","      (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (1): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (2): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (3): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (4): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","  )\n",")), ('transitions', HybridSequential(\n","  (0): HybridSequential(\n","    (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","    (2): LeakyReLU(0.1)\n","  )\n","  (1): HybridSequential(\n","    (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","    (2): LeakyReLU(0.1)\n","  )\n",")), ('yolo_blocks', HybridSequential(\n","  (0): YOLODetectionBlockV3(\n","    (body): HybridSequential(\n","      (0): HybridSequential(\n","        (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (1): HybridSequential(\n","        (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (2): HybridSequential(\n","        (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (3): HybridSequential(\n","        (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (4): HybridSequential(\n","        (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","    )\n","    (tip): HybridSequential(\n","      (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","      (2): LeakyReLU(0.1)\n","    )\n","  )\n","  (1): YOLODetectionBlockV3(\n","    (body): HybridSequential(\n","      (0): HybridSequential(\n","        (0): Conv2D(768 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (1): HybridSequential(\n","        (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (2): HybridSequential(\n","        (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (3): HybridSequential(\n","        (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (4): HybridSequential(\n","        (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","    )\n","    (tip): HybridSequential(\n","      (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","      (2): LeakyReLU(0.1)\n","    )\n","  )\n","  (2): YOLODetectionBlockV3(\n","    (body): HybridSequential(\n","      (0): HybridSequential(\n","        (0): Conv2D(384 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (1): HybridSequential(\n","        (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (2): HybridSequential(\n","        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (3): HybridSequential(\n","        (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (4): HybridSequential(\n","        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","        (2): LeakyReLU(0.1)\n","      )\n","    )\n","    (tip): HybridSequential(\n","      (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","      (2): LeakyReLU(0.1)\n","    )\n","  )\n",")), ('yolo_outputs', HybridSequential(\n","  (0): YOLOOutputV3(\n","    (prediction): Conv2D(1024 -> 75, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (1): YOLOOutputV3(\n","    (prediction): Conv2D(512 -> 75, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (2): YOLOOutputV3(\n","    (prediction): Conv2D(256 -> 75, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","))]), '_reg_params': {}, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_cached_graph': (), '_cached_op': None, '_cached_op_args': [], '_out_format': None, '_in_format': None, '_active': False, '_flags': [], '_callback': None, '_monitor_all': False, '_backend': None, '_backend_opts': {}, '_classes': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'), 'nms_thresh': 0.45, 'nms_topk': 400, 'post_nms': 100, '_pos_iou_thresh': 1.0, '_ignore_iou_thresh': 0.7, '_target_generator': YOLOV3TargetMerger(\n","  (_dynamic_target): YOLOV3DynamicTargetGeneratorSimple(\n","    (_batch_iou): BBoxBatchIOU(\n","      (_pre): BBoxSplit(\n","      \n","      )\n","    )\n","  )\n","), '_loss': YOLOV3Loss(batch_axis=0, w=None), 'stages': HybridSequential(\n","  (0): HybridSequential(\n","    (0): HybridSequential(\n","      (0): Conv2D(3 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (1): HybridSequential(\n","      (0): Conv2D(32 -> 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (2): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(64 -> 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(32 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (3): HybridSequential(\n","      (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (4): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(128 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (5): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(128 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(64 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (6): HybridSequential(\n","      (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (7): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (8): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (9): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (10): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (11): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (12): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (13): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (14): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","  )\n","  (1): HybridSequential(\n","    (0): HybridSequential(\n","      (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (1): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (2): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (3): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (4): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (5): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (6): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (7): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (8): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","  )\n","  (2): HybridSequential(\n","    (0): HybridSequential(\n","      (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","      (2): LeakyReLU(0.1)\n","    )\n","    (1): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (2): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (3): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","    (4): DarknetBasicBlockV3(\n","      (body): HybridSequential(\n","        (0): HybridSequential(\n","          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","          (2): LeakyReLU(0.1)\n","        )\n","        (1): HybridSequential(\n","          (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","          (2): LeakyReLU(0.1)\n","        )\n","      )\n","    )\n","  )\n","), 'transitions': HybridSequential(\n","  (0): HybridSequential(\n","    (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","    (2): LeakyReLU(0.1)\n","  )\n","  (1): HybridSequential(\n","    (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","    (2): LeakyReLU(0.1)\n","  )\n","), 'yolo_blocks': HybridSequential(\n","  (0): YOLODetectionBlockV3(\n","    (body): HybridSequential(\n","      (0): HybridSequential(\n","        (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (1): HybridSequential(\n","        (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (2): HybridSequential(\n","        (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (3): HybridSequential(\n","        (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (4): HybridSequential(\n","        (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","    )\n","    (tip): HybridSequential(\n","      (0): Conv2D(512 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n","      (2): LeakyReLU(0.1)\n","    )\n","  )\n","  (1): YOLODetectionBlockV3(\n","    (body): HybridSequential(\n","      (0): HybridSequential(\n","        (0): Conv2D(768 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (1): HybridSequential(\n","        (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (2): HybridSequential(\n","        (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (3): HybridSequential(\n","        (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (4): HybridSequential(\n","        (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","    )\n","    (tip): HybridSequential(\n","      (0): Conv2D(256 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n","      (2): LeakyReLU(0.1)\n","    )\n","  )\n","  (2): YOLODetectionBlockV3(\n","    (body): HybridSequential(\n","      (0): HybridSequential(\n","        (0): Conv2D(384 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (1): HybridSequential(\n","        (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (2): HybridSequential(\n","        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (3): HybridSequential(\n","        (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","        (2): LeakyReLU(0.1)\n","      )\n","      (4): HybridSequential(\n","        (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n","        (2): LeakyReLU(0.1)\n","      )\n","    )\n","    (tip): HybridSequential(\n","      (0): Conv2D(128 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n","      (2): LeakyReLU(0.1)\n","    )\n","  )\n","), 'yolo_outputs': HybridSequential(\n","  (0): YOLOOutputV3(\n","    (prediction): Conv2D(1024 -> 75, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (1): YOLOOutputV3(\n","    (prediction): Conv2D(512 -> 75, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (2): YOLOOutputV3(\n","    (prediction): Conv2D(256 -> 75, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")}\n"]}]}]}